#!/usr/bin/env python3
"""
èµ„æºå…¨é‡åŒæ­¥è„šæœ¬
åŠŸèƒ½ï¼š
1. æ£€æŸ¥ç›®æ ‡ä»“åº“çš„ data/resource.json æ˜¯å¦æœ‰æ›´æ–°
2. ä¸‹è½½æœ€æ–°çš„ id2role.json
3. æ™ºèƒ½ä¸‹è½½è§’è‰²å›¾ç‰‡ (GitHubä¼˜å…ˆ -> hakush.inå¤‡ç”¨)
4. ç”Ÿæˆæœ€ç»ˆçš„ src/role.json
"""

import io
import json
import logging
import sys
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Any

import requests
from PIL import Image

# ---------- åŸºç¡€é…ç½® ----------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s: %(message)s",
    datefmt="%H:%M:%S",
)

TARGET_REPO = "MoonShadow1976/WutheringWaves_OverSea_StaticAssets"
STATE_FILE = Path(".github/asset_sync_state.json")

SOURCE_JSON_URL = "https://api.hakush.in/ww/data/character.json"
LOCAL_JSON_PATH = Path("src/id2role.json")

ROLE_IMG_API_URL = (
    f"https://api.github.com/repos/{TARGET_REPO}/contents/data/resource/role_pile"
)
ROLE_PILE_JSON_URL = (
    f"https://raw.githubusercontent.com/{TARGET_REPO}/main/data/resource/role_pile.json"
)
LOCAL_IMG_DIR = Path("src/role/")

# hakush.in å¤‡ç”¨ä¸‹è½½é…ç½®
HAKUSH_MAIN_URL = "https://api.hakush.in/ww"
ROLE_PILE_PATH = LOCAL_IMG_DIR  # ç»Ÿä¸€å›¾ç‰‡è¾“å‡ºç›®å½•


# ---------- çŠ¶æ€ç®¡ç† ----------
def load_state() -> dict[str, Any]:
    """åŠ è½½ä¸Šæ¬¡åŒæ­¥çš„çŠ¶æ€è®°å½•"""
    try:
        with open(STATE_FILE, encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return {"last_updated": None, "last_checked": None}


def save_state(key: str, value: Any):
    """ä¿å­˜æœ¬æ¬¡åŒæ­¥çŠ¶æ€"""
    state = load_state()
    state[key] = value
    STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, indent=2, ensure_ascii=False)


# ---------- æ ¸å¿ƒæ£€æŸ¥å‡½æ•° ----------
def check_for_updates() -> tuple[bool, str | None]:
    """
    æ£€æŸ¥ç›®æ ‡ä»“åº“æ˜¯å¦æœ‰æ›´æ–°
    è¿”å›: (æ˜¯å¦æ›´æ–°, æœ€æ–°æ—¶é—´æˆ³/None)
    """
    logging.info("ğŸ” æ£€æŸ¥ç›®æ ‡ä»“åº“æ›´æ–°...")
    try:
        # 1. è·å–ç›®æ ‡æ–‡ä»¶çš„åŸå§‹å†…å®¹
        resp = requests.get(ROLE_PILE_JSON_URL, timeout=30)
        resp.raise_for_status()
        current_data = resp.json()
        current_time = current_data.get("last_updated")

        # 2. è·å–ä¸Šæ¬¡è®°å½•çš„çŠ¶æ€
        last_state = load_state()
        last_sync_time = last_state.get("last_updated")

        # 3. æ¯”è¾ƒåˆ¤æ–­
        if not current_time:
            logging.warning("âš ï¸  ç›®æ ‡æ–‡ä»¶æœªæ‰¾åˆ°æ—¶é—´æˆ³ï¼Œå°†å°è¯•åŒæ­¥")
            return True, datetime.now(timezone.utc).isoformat()

        if current_time != last_sync_time:
            logging.info(f"âœ… å‘ç°æ›´æ–°! æ—§: {last_sync_time}, æ–°: {current_time}")
            return True, current_time
        else:
            logging.info(f"â­ï¸  æ— æ–°æ›´æ–°ã€‚ä¸Šæ¬¡åŒæ­¥: {last_sync_time}")
            return False, current_time

    except requests.RequestException as e:
        logging.error(f"âŒ æ£€æŸ¥æ›´æ–°å¤±è´¥: {e}")
        # ç½‘ç»œå¤±è´¥æ—¶ï¼Œä¿å®ˆèµ·è§å°è¯•åŒæ­¥
        return True, f"error_{datetime.now(timezone.utc).isoformat()}"


# ---------- JSONä¸‹è½½ ----------
def download_json() -> bool:
    """ä¸‹è½½å¹¶ä¿å­˜è§’è‰²JSONæ–‡ä»¶ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
    logging.info("ğŸ“¥ ä¸‹è½½è§’è‰²JSON...")
    try:
        resp = requests.get(SOURCE_JSON_URL, timeout=30)
        resp.raise_for_status()
        data = resp.json()

        LOCAL_JSON_PATH.parent.mkdir(parents=True, exist_ok=True)
        with open(LOCAL_JSON_PATH, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        logging.info(f"âœ… JSONå·²ä¿å­˜è‡³: {LOCAL_JSON_PATH}")
        return True
    except Exception as e:
        logging.error(f"âŒ ä¸‹è½½JSONå¤±è´¥: {e}")
        return False


# ---------- å›¾ç‰‡ä¸‹è½½ (GitHubä¼˜å…ˆ) ----------
def download_from_github() -> tuple[int, int]:
    """
    ä»GitHubä»“åº“ä¸‹è½½å›¾ç‰‡ï¼Œä¼˜å…ˆä½¿ç”¨ role_pile.json è¿›è¡Œæ–‡ä»¶å¤§å°å¯¹æ¯”
    è¿”å›: (æˆåŠŸæ•°, å¤±è´¥æ•°)
    """
    logging.info("ğŸ–¼ï¸  ä»GitHubä»“åº“åŒæ­¥å›¾ç‰‡ (ä½¿ç”¨æ¸…å•æ–‡ä»¶)...")
    LOCAL_IMG_DIR.mkdir(parents=True, exist_ok=True)

    success, fail = 0, 0
    files_to_download = []  # å­˜å‚¨éœ€è¦ä¸‹è½½çš„æ–‡ä»¶ä¿¡æ¯

    try:
        # 1. ä¼˜å…ˆå°è¯•è·å–å¹¶è§£æ role_pile.json
        pile_resp = requests.get(ROLE_PILE_JSON_URL, timeout=30)

        if pile_resp.status_code == 200:
            try:
                pile_data = pile_resp.json()
                last_updated = pile_data.get("last_updated", "N/A")
                file_list = pile_data.get("files", [])

                logging.info(
                    f"âœ… è·å–åˆ°å›¾ç‰‡æ¸…å•ï¼ŒåŒ…å« {len(file_list)} ä¸ªæ–‡ä»¶ï¼Œæ›´æ–°æ—¶é—´: {last_updated}"
                )

                # åˆ†ææœ¬åœ°æ–‡ä»¶ï¼Œæ„å»ºéœ€è¦ä¸‹è½½çš„åˆ—è¡¨
                for file_info in file_list:
                    filename = file_info.get("name")
                    remote_size = file_info.get("size")

                    if not filename or remote_size is None:
                        continue

                    local_path = LOCAL_IMG_DIR / filename
                    needs_download = True

                    # æ ¸å¿ƒå¯¹æ¯”é€»è¾‘ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¤§å°ä¸€è‡´
                    if local_path.exists():
                        local_size = local_path.stat().st_size
                        if local_size == remote_size:
                            needs_download = False
                            logging.debug(
                                f"â­ï¸  è·³è¿‡ {filename} (å¤§å°ä¸€è‡´: {local_size} bytes)"
                            )

                    if needs_download:
                        # æ„å»ºä¸‹è½½URL (ä½¿ç”¨ raw.githubusercontent.com)
                        download_url = ROLE_PILE_JSON_URL.replace(".json", f"/{filename}")
                        files_to_download.append(
                            {
                                "url": download_url,
                                "local_path": local_path,
                            }
                        )

                logging.info(f"ğŸ“‹ éœ€è¦ä¸‹è½½ {len(files_to_download)} ä¸ªæ–°/æ›´æ–°æ–‡ä»¶")

            except json.JSONDecodeError as e:
                logging.warning(f"âŒ è§£æ role_pile.json å¤±è´¥: {e}ï¼Œå°†å›é€€åˆ°APIæ–¹å¼")
                files_to_download = None  # è§¦å‘å›é€€

        else:
            logging.warning(
                f"âš ï¸  æ— æ³•è·å– role_pile.json (HTTP {pile_resp.status_code})ï¼Œå°†å›é€€åˆ°APIæ–¹å¼"
            )
            files_to_download = None  # è§¦å‘å›é€€

        # 2. å›é€€æ–¹æ¡ˆï¼šå¦‚æœè·å–JSONå¤±è´¥ï¼Œä½¿ç”¨åŸæ¥çš„GitHub APIæ–¹å¼
        if files_to_download is None:
            logging.info("ğŸ”„ å›é€€åˆ°GitHub APIæ–¹å¼è·å–æ–‡ä»¶åˆ—è¡¨...")
            files_to_download = []
            try:
                resp = requests.get(ROLE_IMG_API_URL, timeout=30)
                resp.raise_for_status()

                if isinstance(resp.json(), dict) and "message" in resp.json():
                    logging.error(f"âŒ GitHub APIé”™è¯¯: {resp.json()['message']}")
                    return 0, 1

                files = resp.json()
                for item in files:
                    if item["type"] != "file":
                        continue

                    filename = item["name"]
                    download_url = item.get("download_url")
                    remote_size = item.get("size")

                    if not download_url:
                        continue

                    local_path = LOCAL_IMG_DIR / filename

                    # å¤§å°æ¯”è¾ƒ
                    if local_path.exists() and remote_size:
                        local_size = local_path.stat().st_size
                        if local_size == remote_size:
                            continue

                    files_to_download.append(
                        {
                            "url": download_url,
                            "local_path": local_path,
                        }
                    )

                logging.info(f"ğŸ“‹ (å›é€€æ–¹å¼) éœ€è¦ä¸‹è½½ {len(files_to_download)} ä¸ªæ–‡ä»¶")

            except Exception as e:
                logging.error(f"âŒ GitHub APIå›é€€æ–¹å¼ä¹Ÿå¤±è´¥: {e}")
                return 0, 1

        # 3. æ‰§è¡Œä¸‹è½½
        if files_to_download:
            logging.info(f"ğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(files_to_download)} ä¸ªæ–‡ä»¶...")

            for file_info in files_to_download:
                download_url = file_info["url"]
                local_path = file_info["local_path"]

                try:
                    img_resp = requests.get(download_url, timeout=60)
                    img_resp.raise_for_status()

                    with open(local_path, "wb") as f:
                        f.write(img_resp.content)

                    success += 1
                    logging.info(f"  âœ… å·²ä¸‹è½½: {local_path}")

                    # é¿å…è¯·æ±‚è¿‡å¿«
                    if len(files_to_download) > 10:
                        time.sleep(0.1)

                except Exception as e:
                    logging.error(f"  âŒ ä¸‹è½½å¤±è´¥ {local_path}: {e}")
                    fail += 1

        return success, fail

    except Exception as e:
        logging.error(f"âŒ GitHubä¸‹è½½æµç¨‹å¤±è´¥: {e}")
        return 0, 1


# ---------- å¤‡ç”¨ä¸‹è½½ (hakush.in) ----------
def download_from_hakush_backup() -> tuple[int, int]:
    """
    ä»hakush.inå¤‡ç”¨æºä¸‹è½½ç¼ºå¤±çš„å›¾ç‰‡
    éœ€è¦ id2role.json ä¸­çš„ icon å­—æ®µ
    è¿”å›: (æˆåŠŸæ•°, å¤±è´¥æ•°)
    """
    logging.info("ğŸ”„ å°è¯•ä»å¤‡ç”¨æº(hakush.in)ä¸‹è½½ç¼ºå¤±å›¾ç‰‡...")

    # 1. åŠ è½½id2role.jsonæ•°æ®
    if not LOCAL_JSON_PATH.exists():
        logging.error("âŒ æ— æ³•ä½¿ç”¨å¤‡ç”¨æº: id2role.json ä¸å­˜åœ¨")
        return 0, 0

    try:
        with open(LOCAL_JSON_PATH, encoding="utf-8") as f:
            id2role_data = json.load(f)
    except Exception as e:
        logging.error(f"âŒ è¯»å–id2role.jsonå¤±è´¥: {e}")
        return 0, 0

    # 2. å‡†å¤‡ä¸‹è½½
    success, fail = 0, 0
    download_tasks = []

    for char_id, char_info in id2role_data.items():
        expected_filename = f"role_pile_{char_id}.png"
        local_path = LOCAL_IMG_DIR / expected_filename

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡
        if local_path.exists():
            continue

        # æ„å»ºå¤‡ç”¨ä¸‹è½½URL (WebPæ ¼å¼)
        icon_path = char_info.get("background", "")
        if not icon_path:
            logging.warning(f"è§’è‰² {char_id} æ— backgroundå­—æ®µï¼Œè·³è¿‡")
            continue

        # å¤„ç†è·¯å¾„ï¼šç§»é™¤å‰ç¼€å’Œæ–‡ä»¶æ‰©å±•å
        resource_path = str(icon_path).split(".")[0].replace("/Game/Aki/", "")
        webp_url = f"{HAKUSH_MAIN_URL}/{resource_path}.webp"
        download_tasks.append((char_id, webp_url, local_path))

    if not download_tasks:
        logging.info("â­ï¸  æ— ç¼ºå¤±å›¾ç‰‡éœ€è¦ä»å¤‡ç”¨æºä¸‹è½½")
        return 0, 0

    logging.info(f"ğŸ“‹ ä»å¤‡ç”¨æºä¸‹è½½ {len(download_tasks)} ä¸ªç¼ºå¤±å›¾ç‰‡")

    # 3. æ‰§è¡Œä¸‹è½½ï¼ˆå¸¦é‡è¯•ï¼‰
    for char_id, webp_url, local_path in download_tasks:
        max_retries = 3
        downloaded = False

        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    wait_time = 2 ** (attempt - 1)  # æŒ‡æ•°é€€é¿: 1, 2, 4ç§’
                    logging.debug(f"ç¬¬{attempt}æ¬¡é‡è¯• ({wait_time}ç§’å): {char_id}")
                    time.sleep(wait_time)

                # ä¸‹è½½WebPå›¾ç‰‡
                resp = requests.get(webp_url, timeout=30)
                resp.raise_for_status()

                # è½¬æ¢ä¸ºPNGæ ¼å¼ä¿å­˜
                webp_image = Image.open(io.BytesIO(resp.content))
                rgb_image = webp_image.convert("RGB")
                rgb_image.save(local_path, "PNG")

                success += 1
                downloaded = True
                logging.info(f"  âœ… å¤‡ç”¨æºä¸‹è½½: {char_id} -> {local_path.name}")
                break

            except Exception as e:
                if attempt == max_retries:
                    logging.error(f"  âŒ å¤‡ç”¨æºä¸‹è½½å¤±è´¥ {char_id}: {e}")
                    fail += 1
                continue

        # çŸ­æš‚æš‚åœï¼Œé¿å…è¯·æ±‚è¿‡å¿«
        if downloaded and len(download_tasks) > 5:
            time.sleep(0.5)

    return success, fail


# ---------- ç”Ÿæˆæœ€ç»ˆrole.json ----------
def generate_final_role_json():
    """æ ¹æ®id2role.jsonå’Œæœ¬åœ°å›¾ç‰‡ç”Ÿæˆæœ€ç»ˆçš„role.json"""
    logging.info("ğŸ“„ ç”Ÿæˆæœ€ç»ˆrole.json...")

    # è¯»å–id2role.json
    if not LOCAL_JSON_PATH.exists():
        logging.error("âŒ æ— æ³•ç”Ÿæˆrole.json: id2role.json ä¸å­˜åœ¨")
        return False

    try:
        with open(LOCAL_JSON_PATH, encoding="utf-8") as f:
            id2role_data = json.load(f)
    except Exception as e:
        logging.error(f"âŒ è¯»å–id2role.jsonå¤±è´¥: {e}")
        return False

    # æ„å»ºæ•°æ®
    data = []
    for char_id, char_info in id2role_data.items():
        # æ£€æŸ¥å¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        expected_filename = f"role_pile_{char_id}.png"
        local_img_path = LOCAL_IMG_DIR / expected_filename

        # æ„å»ºè§’è‰²æ•°æ®
        char_data = {
            "id": char_id,
            "url": f"src/role/{expected_filename}" if local_img_path.exists() else None,
        }

        # æ·»åŠ å¤šè¯­è¨€åç§°
        for lang, name in char_info.items():
            if lang in ["icon", "background", "rank", "weapon", "element", "desc"]:
                continue
            if lang == "zh-Hans":
                lang_key = "zh"
            else:
                lang_key = lang
            char_data[lang_key] = name

        data.append(char_data)

    # æ„å»ºæœ€ç»ˆç»“æ„
    result = {
        "status": 200,
        "info": "Wuthering Waves Role Data",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "data": data,
    }

    # ä¿å­˜æ–‡ä»¶
    output_path = Path("src/role.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    logging.info(f"âœ… role.json å·²ç”Ÿæˆ: {output_path}")
    logging.info(f"   åŒ…å« {len(data)} ä¸ªè§’è‰²æ•°æ®")
    return True


# ---------- ä¸»å‡½æ•° ----------
def main():
    print("=" * 60)
    print("é¸£æ½®èµ„æºå…¨é‡åŒæ­¥è„šæœ¬")
    print("=" * 60)

    # 1. æ£€æŸ¥æ›´æ–°
    has_update, new_timestamp = check_for_updates()
    if not has_update:
        logging.info("ğŸ”„ æœªå‘ç°æ–°å†…å®¹ï¼Œæœ¬æ¬¡åŒæ­¥ç»“æŸã€‚")
        save_state("last_checked", datetime.now(timezone.utc).isoformat())
        sys.exit(0)

    logging.info("ğŸš€ å¼€å§‹åŒæ­¥æµç¨‹...")

    # 2. ä¸‹è½½JSONæ•°æ®
    if not download_json():
        logging.error("âŒ JSONä¸‹è½½å¤±è´¥ï¼ŒåŒæ­¥ç»ˆæ­¢")
        sys.exit(1)

    # 3. å›¾ç‰‡ä¸‹è½½ï¼šGitHubä¼˜å…ˆ
    logging.info("\n" + "-" * 50)
    gh_success, gh_fail = download_from_github()

    # 4. å¤‡ç”¨ä¸‹è½½ï¼šå¦‚æœæœ‰å¤±è´¥æˆ–ç¼ºå¤±
    if gh_fail > 0 or gh_success == 0:
        logging.info("\n" + "-" * 50)
        backup_success, backup_fail = download_from_hakush_backup()
        total_success = gh_success + backup_success
        total_fail = gh_fail + backup_fail
    else:
        total_success = gh_success
        total_fail = gh_fail

    # 5. ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶
    logging.info("\n" + "-" * 50)
    if not generate_final_role_json():
        logging.warning("âš ï¸  ç”Ÿæˆrole.jsonå¤±è´¥ï¼Œä½†å…¶ä»–åŒæ­¥å·²å®Œæˆ")

    # 6. ä¿å­˜çŠ¶æ€
    save_state("last_updated", new_timestamp)
    save_state("last_synced", datetime.now(timezone.utc).isoformat())
    save_state(
        "last_sync_stats",
        {
            "images_downloaded": total_success,
            "images_failed": total_fail,
            "timestamp": new_timestamp,
        },
    )

    # 7. è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 60)
    print("âœ… åŒæ­¥å®Œæˆï¼")
    print(f"   å›¾ç‰‡: æˆåŠŸ {total_success}, å¤±è´¥ {total_fail}")
    print("   æ•°æ®: id2role.json, role.json")
    print(f"   çŠ¶æ€: å·²æ›´æ–°è‡³æ—¶é—´æˆ³ {new_timestamp}")
    print("=" * 60)

    # æç¤ºï¼šå¦‚æœtotal_fail>0ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ£€æŸ¥
    if total_fail > 0:
        print(f"\nâš ï¸  æ³¨æ„: æœ‰ {total_fail} ä¸ªå›¾ç‰‡ä¸‹è½½å¤±è´¥")
        print("     å°†åœ¨ä¸‹æ¬¡åŒæ­¥æ—¶é‡è¯•")


if __name__ == "__main__":
    main()
